{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bcac0e",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee30d68",
   "metadata": {},
   "source": [
    "La ProCam s.p.a ha intenzione di lanciare sul mercato una nuova fotocamera digitale compatta ed economica destinata a piccoli fotografi in erba.\n",
    "\n",
    "Vieni assunto come Data Scientist per realizzare il sistema di identificazione dei volti nelle immagini, questo permetterà poi ai tecnici della fotografia di ottimizzare le impostazioni per un selfie con una o più persone.\n",
    "\n",
    "Si tratta di un problema di computer vision, più precisamente di Face Detection.\n",
    "\n",
    "Devi fornire una pipeline scikit-learn che prende un'immagine in ingresso e ritorna una lista con le coordinate dei bounding box dove sono presenti dei volti, se nell'immagine non contiene volti la lista sarà ovviamente vuota."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa0e31",
   "metadata": {},
   "source": [
    "- Non ti viene fornito un dataset, sta a te cercarne uno in rete o, nella peggiore delle ipotesi, costruirlo, per semplicità non considereremo implicazioni sulle licenze ad utilizzo commerciale, si tratta pur sempre di un progetto didattico.\n",
    "- Non puoi utilizzare modelli pre-addestrati, devi addestrarlo tu utilizzando scikit-learn.\n",
    "- Stai lavorando su un sistema con ridotte capacità di calcolo, quindi il modello deve richiedere poche risorse di calcolo.\n",
    "- Ovviamente non ti vengono fornite indicazioni sull'implementazione, fai un'approfondita ricerca bibliografica per trovare la soluzione migliore da adottare, il notebook che consegnerai deve essere ben documentato, devi spiegare quali soluzioni hai adottato e perché ed ogni risorsa esterna (paper, blog post, codice github...) che hai utilizzato.\n",
    "- Il progetto è abbastanza complesso, ricorda che in caso ne avessi necessità puoi sempre chiedere aiuto ai tuoi coach nella Classe Virtuale di Machine Learning su Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee4416",
   "metadata": {},
   "source": [
    "# Notebook 1\n",
    "## Model construction, optimization and training\n",
    "\n",
    "In this notebook the model is built, optimized and trained.\n",
    "\n",
    "First of all, the images dataset for training, validation and test is built, gathering several datasets found in kaggle and scikit-learn library; then a Pipeline is made in order to perform images preprocessing, feature extraction, dimensionality reduction and finally prediction through a SVM model.\n",
    "An hyper parameter tuning is performed with random search technique.\n",
    "\n",
    "At the end of this notebook the optimized pipeline is saved into a joblib file, for further usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa02d45",
   "metadata": {},
   "source": [
    "### Bash section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1d8fb",
   "metadata": {},
   "source": [
    "Install kaggle package (inf not already installed) and import non-face images from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c69ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\aless\\anaconda3\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\aless\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\aless\\anaconda3\\lib\\site-packages (from kaggle) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\aless\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\aless\\anaconda3\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aless\\anaconda3\\lib\\site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\aless\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\aless\\anaconda3\\lib\\site-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in c:\\users\\aless\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\aless\\appdata\\roaming\\python\\python311\\site-packages (from bleach->kaggle) (23.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\aless\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\aless\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aless\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aless\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aless\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5941a",
   "metadata": {},
   "source": [
    "As negative class images (i.e. non-face images) the [African Wildlife dataset](https://www.kaggle.com/datasets/biancaferreira/african-wildlife) is used. \n",
    "\n",
    "This is a collection of 4 african animals images, taken from Google images.\n",
    "\n",
    "Inspecting images, one can see as in images there is also some natural background, and could be useful for learning not only animal features but even natural objects ones too (such as trees and rocks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b04e3d",
   "metadata": {},
   "source": [
    "Dataset is downloded through kaggle API and extracted into a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feab04cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/biancaferreira/african-wildlife\n",
      "License(s): unknown\n",
      "african-wildlife.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p wildlife biancaferreira/african-wildlife\n",
    "!tar -xf wildlife/african-wildlife.zip -C wildlife"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd49ec6",
   "metadata": {},
   "source": [
    "### Python section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83836c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some modules\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ImageResizer import ImageResizer\n",
    "from HOGFeatureExtractor import HOGFeatureExtractor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d267af9",
   "metadata": {},
   "source": [
    "Set a random seed to get reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2178e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=200\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f770e70",
   "metadata": {},
   "source": [
    "#### Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e9d7",
   "metadata": {},
   "source": [
    "As positive class images (i.e. faces images) the [Olivetti faces dataset](https://scikit-learn.org/stable/datasets/real_world.html#the-olivetti-faces-dataset) is used.\n",
    "\n",
    "This dataset is a collection of 10 photos of each of 40 distinct subjects faces (400 samples total). \n",
    "\n",
    "This dataset is very suitable for face detection learning, since images are very clean, there aren't distracting elements (like background) and faces are depicted with different facial expressions (open/closed eyes, smiling/not smiling) and frontal position.\n",
    "\n",
    "This is perfect for a SVM classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78c45a",
   "metadata": {},
   "source": [
    "The dataset is downloaded with the [scikit-learn utility](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232acb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "olivetti_faces=fetch_olivetti_faces()\n",
    "\n",
    "images_positive = olivetti_faces.images\n",
    "\n",
    "#helper variable\n",
    "resize_shape = (64, 64) #as row x columns (h x w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4379d",
   "metadata": {},
   "source": [
    "Store positive images in a temporary variable and generate positive labels array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d886e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 64, 64)\n",
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "X_positive = images_positive\n",
    "y_positive = np.ones(X_positive.shape[0])\n",
    "\n",
    "#check\n",
    "print(X_positive.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d17292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64)\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "print(X_positive[1,:,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de34d0e",
   "metadata": {},
   "source": [
    "Store negative images in a temporary variable and generate negative labels array.\n",
    "\n",
    "Note: not all images available in kaggle dataset are used, but for each subdirectory (i.e. images set for a given animal) the images provided are randomly sampled, such that there will be 100 images for each animal, and so 400 negative images in total in final dataset.\n",
    "\n",
    "This is done to have a balanced dataset between positive and negative classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b73df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing negative images (wildlife/buffalo): 100%|██████████| 100/100 [00:10<00:00,  9.48item/s]\n",
      "Processing negative images (wildlife/elephant): 100%|██████████| 100/100 [00:03<00:00, 26.61item/s]\n",
      "Processing negative images (wildlife/rhino): 100%|██████████| 100/100 [00:05<00:00, 18.31item/s]\n",
      "Processing negative images (wildlife/zebra): 100%|██████████| 100/100 [00:03<00:00, 27.47item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 64, 64)\n",
      "(400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#process negative images V2\n",
    "negative_images = []\n",
    "\n",
    "buffalo_img_dir = \"wildlife/buffalo\"\n",
    "elephant_img_dir = \"wildlife/elephant\"\n",
    "rhino_img_dir = \"wildlife/rhino\"\n",
    "zebra_img_dir = \"wildlife/zebra\"\n",
    "\n",
    "negative_img_dirs = [buffalo_img_dir,\n",
    "                     elephant_img_dir,\n",
    "                     rhino_img_dir,\n",
    "                     zebra_img_dir                 \n",
    "                    ]\n",
    "\n",
    "for directory in negative_img_dirs:\n",
    "    filenames = os.listdir(directory)\n",
    "    jpg_files = [f for f in filenames if f.endswith('.jpg')]\n",
    "    #with 4 directories I get 400 negative images that balance positive images numerosity (400) \n",
    "    sampled_files=random.sample(jpg_files,100)\n",
    "\n",
    "\n",
    "    for filename in tqdm(sampled_files,desc=f\"Processing negative images ({directory})\",\n",
    "                        unit=\"item\"):\n",
    "        \n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = imread(img_path, as_gray=True)\n",
    "            #this resize is necessary for concatenation in a single numpy array\n",
    "            img = resize(img, X_positive[1,:,:].shape)\n",
    "            negative_images.append(img)\n",
    "\n",
    "X_negative = np.array(negative_images)\n",
    "y_negative = np.zeros(X_negative.shape[0])\n",
    "\n",
    "#check\n",
    "print(X_negative.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_negative.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c043127",
   "metadata": {},
   "source": [
    "Store whole dataset in a single matrix and labels array. Here we follow the convention to call _X_ the obervation matrix and _y_ the labels array.\n",
    "\n",
    "The idea is to pass dataset to a scikit-learn Pipeline, in a conventional way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399b397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 64, 64)\n",
      "(800,)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((X_positive, X_negative))\n",
    "y = np.concatenate([y_positive,y_negative])\n",
    "\n",
    "#check\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e93d9",
   "metadata": {},
   "source": [
    "#### Pipeline definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0986a049",
   "metadata": {},
   "source": [
    "All the preprocessing, feature extraction and classification steps are integrated inside a Pipeline, in order to generate an object that can be easly shared and used, even among different devices or notebooks.\n",
    "\n",
    "Pipeline steps are:\n",
    "- ImageResizer\n",
    "    \n",
    "    A custom transformer, used to resize input images\n",
    "- HOGFeatureExtractor\n",
    "    \n",
    "    A custom transformer, used to perform feature extraction using the [HOG method](https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/)\n",
    "- StandardScaler\n",
    "\n",
    "    Standard scikit-learn implementation of data standardization. This is crucial for subsequent PCA step.\n",
    "- PCA\n",
    "    \n",
    "    Once the images are transformed into numeric features, a dimensionality reduction is performed since HOG method generates a lot of features and here we need to make a light model due to limited computational resources\n",
    "- SVC\n",
    "    \n",
    "    Scikit-learn implementation of SVM model. This last step performs classification.\n",
    "\n",
    "The pipeline is created with a cache functionality (see memory parameter in [Pipeline documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)) to increase memory efficency during optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e26070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=&#x27;pipe_cache&#x27;,\n",
       "         steps=[(&#x27;resizer&#x27;, ImageResizer(resize_shape=(64, 64))),\n",
       "                (&#x27;hog&#x27;, HOGFeatureExtractor()), (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(random_state=200)), (&#x27;svc&#x27;, SVC(max_iter=5000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=&#x27;pipe_cache&#x27;,\n",
       "         steps=[(&#x27;resizer&#x27;, ImageResizer(resize_shape=(64, 64))),\n",
       "                (&#x27;hog&#x27;, HOGFeatureExtractor()), (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(random_state=200)), (&#x27;svc&#x27;, SVC(max_iter=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ImageResizer</label><div class=\"sk-toggleable__content\"><pre>ImageResizer(resize_shape=(64, 64))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HOGFeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>HOGFeatureExtractor()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(random_state=200)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(max_iter=5000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory='pipe_cache',\n",
       "         steps=[('resizer', ImageResizer(resize_shape=(64, 64))),\n",
       "                ('hog', HOGFeatureExtractor()), ('scaler', StandardScaler()),\n",
       "                ('pca', PCA(random_state=200)), ('svc', SVC(max_iter=5000))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('resizer', ImageResizer(resize_shape)),\n",
    "    ('hog', HOGFeatureExtractor()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(random_state=RANDOM_SEED)), \n",
    "    ('svc', SVC(max_iter=5000))\n",
    "], \n",
    "memory=\"pipe_cache\")\n",
    "\n",
    "#check\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d285c",
   "metadata": {},
   "source": [
    "#### Pipeline optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973db46a",
   "metadata": {},
   "source": [
    "Hyper parameters optimization is done by [Random search method](https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-search). \n",
    "\n",
    "The parameters that are optmized are:\n",
    "- n_components of PCA step\n",
    "- C parameter of SVC step\n",
    "\n",
    "Gamma and kernel of SVM are constant, and here we use rbf as kernel, and the default scikit-learn gamma value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c33b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniform distribution, such that all values are equally probable\n",
    "C_range = uniform(loc=0.001, scale=100.0)\n",
    "n_components_range=[100,150,200,250]\n",
    "\n",
    "grid = [{\n",
    "    \"pca__n_components\":n_components_range,\n",
    "    \"svc__kernel\" : [\"rbf\"],\n",
    "    \"svc__C\" : C_range\n",
    "}]\n",
    "\n",
    "search = RandomizedSearchCV(estimator=pipeline,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=4,\n",
    "                            random_state=RANDOM_SEED,\n",
    "                            n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "196fa0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 64, 64)\n",
      "(160, 64, 64)\n",
      "(640,)\n",
      "(160,)\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END pca__n_components=200, svc__C=49.41536292718904, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=200, svc__C=49.41536292718904, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=200, svc__C=49.41536292718904, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=200, svc__C=49.41536292718904, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=200, svc__C=49.41536292718904, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=100, svc__C=59.443014439113256, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END pca__n_components=100, svc__C=59.443014439113256, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=100, svc__C=59.443014439113256, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END pca__n_components=100, svc__C=59.443014439113256, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END pca__n_components=100, svc__C=59.443014439113256, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=100, svc__C=57.39414762066355, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END pca__n_components=100, svc__C=57.39414762066355, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=100, svc__C=57.39414762066355, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END pca__n_components=100, svc__C=57.39414762066355, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END pca__n_components=100, svc__C=57.39414762066355, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END pca__n_components=200, svc__C=0.287059168094277, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=200, svc__C=0.287059168094277, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=200, svc__C=0.287059168094277, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=200, svc__C=0.287059168094277, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=200, svc__C=0.287059168094277, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END pca__n_components=150, svc__C=43.579580699633716, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=150, svc__C=43.579580699633716, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=150, svc__C=43.579580699633716, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=150, svc__C=43.579580699633716, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=150, svc__C=43.579580699633716, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=200, svc__C=45.60909854582528, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=200, svc__C=45.60909854582528, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=200, svc__C=45.60909854582528, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 4/5] END pca__n_components=200, svc__C=45.60909854582528, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=200, svc__C=45.60909854582528, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=250, svc__C=96.7485666607596, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=250, svc__C=96.7485666607596, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=250, svc__C=96.7485666607596, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=250, svc__C=96.7485666607596, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=250, svc__C=96.7485666607596, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=150, svc__C=98.60375114020934, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=150, svc__C=98.60375114020934, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=150, svc__C=98.60375114020934, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=150, svc__C=98.60375114020934, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=150, svc__C=98.60375114020934, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=200, svc__C=70.68195825887719, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=200, svc__C=70.68195825887719, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=200, svc__C=70.68195825887719, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=200, svc__C=70.68195825887719, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=200, svc__C=70.68195825887719, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=100, svc__C=84.61134903175555, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=100, svc__C=84.61134903175555, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=100, svc__C=84.61134903175555, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=100, svc__C=84.61134903175555, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=100, svc__C=84.61134903175555, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=200, svc__C=18.723056437713122, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=200, svc__C=18.723056437713122, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=200, svc__C=18.723056437713122, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=200, svc__C=18.723056437713122, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 5/5] END pca__n_components=200, svc__C=18.723056437713122, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END pca__n_components=250, svc__C=25.05150547710023, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=250, svc__C=25.05150547710023, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=250, svc__C=25.05150547710023, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=250, svc__C=25.05150547710023, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=250, svc__C=25.05150547710023, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=250, svc__C=51.73622229752766, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=250, svc__C=51.73622229752766, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=250, svc__C=51.73622229752766, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=250, svc__C=51.73622229752766, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=250, svc__C=51.73622229752766, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END pca__n_components=250, svc__C=82.60601471973274, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END pca__n_components=250, svc__C=82.60601471973274, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=250, svc__C=82.60601471973274, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=250, svc__C=82.60601471973274, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=250, svc__C=82.60601471973274, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=250, svc__C=81.66296187846393, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=250, svc__C=81.66296187846393, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=250, svc__C=81.66296187846393, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=250, svc__C=81.66296187846393, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=250, svc__C=81.66296187846393, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=100, svc__C=57.8385690105367, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=100, svc__C=57.8385690105367, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=100, svc__C=57.8385690105367, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=100, svc__C=57.8385690105367, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=100, svc__C=57.8385690105367, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=200, svc__C=56.77450437652839, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=200, svc__C=56.77450437652839, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=200, svc__C=56.77450437652839, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=200, svc__C=56.77450437652839, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=200, svc__C=56.77450437652839, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=250, svc__C=41.94356213164552, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=250, svc__C=41.94356213164552, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=250, svc__C=41.94356213164552, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=250, svc__C=41.94356213164552, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=250, svc__C=41.94356213164552, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 1/5] END pca__n_components=100, svc__C=81.93292899872087, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 2/5] END pca__n_components=100, svc__C=81.93292899872087, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=100, svc__C=81.93292899872087, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=100, svc__C=81.93292899872087, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=100, svc__C=81.93292899872087, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 1/5] END pca__n_components=150, svc__C=10.54441072821876, svc__kernel=rbf;, score=1.000 total time=   0.1s\n",
      "[CV 2/5] END pca__n_components=150, svc__C=10.54441072821876, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 3/5] END pca__n_components=150, svc__C=10.54441072821876, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 4/5] END pca__n_components=150, svc__C=10.54441072821876, svc__kernel=rbf;, score=1.000 total time=   0.2s\n",
      "[CV 5/5] END pca__n_components=150, svc__C=10.54441072821876, svc__kernel=rbf;, score=1.000 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(memory=&#x27;pipe_cache&#x27;,\n",
       "                                      steps=[(&#x27;resizer&#x27;,\n",
       "                                              ImageResizer(resize_shape=(64,\n",
       "                                                                         64))),\n",
       "                                             (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;pca&#x27;, PCA(random_state=200)),\n",
       "                                             (&#x27;svc&#x27;, SVC(max_iter=5000))]),\n",
       "                   n_iter=20, n_jobs=1,\n",
       "                   param_distributions=[{&#x27;pca__n_components&#x27;: [100, 150, 200,\n",
       "                                                               250],\n",
       "                                         &#x27;svc__C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000021BFDAF1ED0&gt;,\n",
       "                                         &#x27;svc__kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "                   random_state=200, scoring=&#x27;accuracy&#x27;, verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(memory=&#x27;pipe_cache&#x27;,\n",
       "                                      steps=[(&#x27;resizer&#x27;,\n",
       "                                              ImageResizer(resize_shape=(64,\n",
       "                                                                         64))),\n",
       "                                             (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;pca&#x27;, PCA(random_state=200)),\n",
       "                                             (&#x27;svc&#x27;, SVC(max_iter=5000))]),\n",
       "                   n_iter=20, n_jobs=1,\n",
       "                   param_distributions=[{&#x27;pca__n_components&#x27;: [100, 150, 200,\n",
       "                                                               250],\n",
       "                                         &#x27;svc__C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000021BFDAF1ED0&gt;,\n",
       "                                         &#x27;svc__kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "                   random_state=200, scoring=&#x27;accuracy&#x27;, verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=&#x27;pipe_cache&#x27;,\n",
       "         steps=[(&#x27;resizer&#x27;, ImageResizer(resize_shape=(64, 64))),\n",
       "                (&#x27;hog&#x27;, HOGFeatureExtractor()), (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(random_state=200)), (&#x27;svc&#x27;, SVC(max_iter=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ImageResizer</label><div class=\"sk-toggleable__content\"><pre>ImageResizer(resize_shape=(64, 64))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HOGFeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>HOGFeatureExtractor()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(random_state=200)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(max_iter=5000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(memory='pipe_cache',\n",
       "                                      steps=[('resizer',\n",
       "                                              ImageResizer(resize_shape=(64,\n",
       "                                                                         64))),\n",
       "                                             ('hog', HOGFeatureExtractor()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('pca', PCA(random_state=200)),\n",
       "                                             ('svc', SVC(max_iter=5000))]),\n",
       "                   n_iter=20, n_jobs=1,\n",
       "                   param_distributions=[{'pca__n_components': [100, 150, 200,\n",
       "                                                               250],\n",
       "                                         'svc__C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x0000021BFDAF1ED0>,\n",
       "                                         'svc__kernel': ['rbf']}],\n",
       "                   random_state=200, scoring='accuracy', verbose=4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=RANDOM_SEED,stratify=y)\n",
    "\n",
    "#check\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3c5c8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'pca__n_components': 200, 'svc__C': 49.41536292718904, 'svc__kernel': 'rbf'}\n",
      "Best accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\")\n",
    "print(f\"Best accuracy: {search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5425bb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=&#x27;pipe_cache&#x27;,\n",
       "         steps=[(&#x27;resizer&#x27;, ImageResizer(resize_shape=(64, 64))),\n",
       "                (&#x27;hog&#x27;, HOGFeatureExtractor()), (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=200, random_state=200)),\n",
       "                (&#x27;svc&#x27;, SVC(C=49.41536292718904, max_iter=5000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=&#x27;pipe_cache&#x27;,\n",
       "         steps=[(&#x27;resizer&#x27;, ImageResizer(resize_shape=(64, 64))),\n",
       "                (&#x27;hog&#x27;, HOGFeatureExtractor()), (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=200, random_state=200)),\n",
       "                (&#x27;svc&#x27;, SVC(C=49.41536292718904, max_iter=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ImageResizer</label><div class=\"sk-toggleable__content\"><pre>ImageResizer(resize_shape=(64, 64))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HOGFeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>HOGFeatureExtractor()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=200, random_state=200)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=49.41536292718904, max_iter=5000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory='pipe_cache',\n",
       "         steps=[('resizer', ImageResizer(resize_shape=(64, 64))),\n",
       "                ('hog', HOGFeatureExtractor()), ('scaler', StandardScaler()),\n",
       "                ('pca', PCA(n_components=200, random_state=200)),\n",
       "                ('svc', SVC(C=49.41536292718904, max_iter=5000))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97153321",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee91b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000        80\n",
      "         1.0     1.0000    1.0000    1.0000        80\n",
      "\n",
      "    accuracy                         1.0000       160\n",
      "   macro avg     1.0000    1.0000    1.0000       160\n",
      "weighted avg     1.0000    1.0000    1.0000       160\n",
      "\n",
      "Confusion matrix on test set\n",
      "[[80  0]\n",
      " [ 0 80]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred,digits=4))\n",
    "\n",
    "print(\"Confusion matrix on test set\")\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b375f52",
   "metadata": {},
   "source": [
    "The optimization produced a very good model, regarding the dataset that has been used: the confusion matrix on test set, doesn't show any prediction error. \n",
    "\n",
    "However, even if the model has an accuracy of $100\\%$ on test set, this doesn't mean that the model will never fail (i.e. make some false positive or false negative predictions) in actual usage. \n",
    "One must keep in mind that the provided dataset doesn't contain all possible non-faces obect images, and the faces in olivetti dataset are always well exposed, hence there could be some errors with real images where faces have high contrast, or are over or under exposed.\n",
    "\n",
    "These aspects are investigated in Notebook 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59912f79",
   "metadata": {},
   "source": [
    "#### Pipeline export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c49ff9",
   "metadata": {},
   "source": [
    "Best found model is exported with joblib module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6582c2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(search.best_estimator_,\"model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
