{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bcac0e",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee30d68",
   "metadata": {},
   "source": [
    "La ProCam s.p.a ha intenzione di lanciare sul mercato una nuova fotocamera digitale compatta ed economica destinata a piccoli fotografi in erba.\n",
    "\n",
    "Vieni assunto come Data Scientist per realizzare il sistema di identificazione dei volti nelle immagini, questo permetterà poi ai tecnici della fotografia di ottimizzare le impostazioni per un selfie con una o più persone.\n",
    "\n",
    "Si tratta di un problema di computer vision, più precisamente di Face Detection.\n",
    "\n",
    "Devi fornire una pipeline scikit-learn che prende un'immagine in ingresso e ritorna una lista con le coordinate dei bounding box dove sono presenti dei volti, se nell'immagine non contiene volti la lista sarà ovviamente vuota."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa0e31",
   "metadata": {},
   "source": [
    "- Non ti viene fornito un dataset, sta a te cercarne uno in rete o, nella peggiore delle ipotesi, costruirlo, per semplicità non considereremo implicazioni sulle licenze ad utilizzo commerciale, si tratta pur sempre di un progetto didattico.\n",
    "- Non puoi utilizzare modelli pre-addestrati, devi addestrarlo tu utilizzando scikit-learn.\n",
    "- Stai lavorando su un sistema con ridotte capacità di calcolo, quindi il modello deve richiedere poche risorse di calcolo.\n",
    "- Ovviamente non ti vengono fornite indicazioni sull'implementazione, fai un'approfondita ricerca bibliografica per trovare la soluzione migliore da adottare, il notebook che consegnerai deve essere ben documentato, devi spiegare quali soluzioni hai adottato e perché ed ogni risorsa esterna (paper, blog post, codice github...) che hai utilizzato.\n",
    "- Il progetto è abbastanza complesso, ricorda che in caso ne avessi necessità puoi sempre chiedere aiuto ai tuoi coach nella Classe Virtuale di Machine Learning su Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e41c2",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83836c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some modules\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from skimage.exposure import rescale_intensity\n",
    "from sklearn.datasets import fetch_lfw_people\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e9d7",
   "metadata": {},
   "source": [
    "Prima di tutto provo a leggere le immagini di esempio di sklearn e provo ad estrarre hog features da questo... Il resto dopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232acb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoort first dataset (faces)\n",
    "lfw_people = fetch_lfw_people(resize=1)\n",
    "\n",
    "images_positive = lfw_people.images\n",
    "#use only a portion of these images, to don't unbalance final dataset\n",
    "# indexes = np.random.choice(len(lfw_people.images),1600, replace=False)\n",
    "# images_positive = lfw_people.images[indexes]\n",
    "\n",
    "#some helper variables\n",
    "#size = 64 x 128 as original paper\n",
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "#init list to hold features arrays and labels\n",
    "features_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e26070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54452793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04661b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fe460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d45aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a4e1cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lfw_people.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d38536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom function to process an image\n",
    "def process_image(img, label):\n",
    "    img_resized = resize(img, resize_shape)\n",
    "    \n",
    "    #feature extraction\n",
    "    #for hog features use same parametes as in original paper\n",
    "    fd, hog_image = hog(img_resized, orientations=9, pixels_per_cell=(8, 8), \n",
    "                        cells_per_block=(2, 2), visualize=True, feature_vector=True)\n",
    "    \n",
    "    #append feature array and labels to helper lists\n",
    "    features_list.append(fd)\n",
    "    labels_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44cf6269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing positive images:: 100%|██████████| 13233/13233 [04:00<00:00, 55.13item/s]\n"
     ]
    }
   ],
   "source": [
    "#process positive images\n",
    "for img in tqdm(images_positive, desc=\"Processing positive images:\", \n",
    "                unit=\"item\"):\n",
    "    process_image(img, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06eb16a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(images_positive.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1d8fb",
   "metadata": {},
   "source": [
    "Import object images from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c69ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc002b2",
   "metadata": {},
   "source": [
    "Butterfly dataset (832 images). \n",
    "\n",
    "It contains bufferflies images with some flowers and plants. With this dataset model can learn to detect naturalistic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cbb93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/veeralakrishna/butterfly-dataset\n",
      "License(s): Community Data License Agreement - Permissive - Version 1.0\n",
      "butterfly-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download veeralakrishna/butterfly-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip butterfly-dataset.zip -d butterfly-dataset\n",
    "!tar -xf butterfly-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072609cc",
   "metadata": {},
   "source": [
    "Background dataset (715 images).\n",
    "\n",
    "It contains some backgournd images, taken from streets and landscape photos. With this dataset model can learn to detect common background objects and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27b96145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sottodirectory o file stanford-background-dataset già esistente.\n"
     ]
    }
   ],
   "source": [
    "!mkdir stanford-background-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5edff9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/balraj98/stanford-background-dataset\n",
      "License(s): other\n",
      "stanford-background-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p stanford-background-dataset balraj98/stanford-background-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18727b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip stanford-background-dataset.zip -d stanford-background-dataset\n",
    "!tar -xf stanford-background-dataset/stanford-background-dataset.zip -C stanford-background-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa93d2a",
   "metadata": {},
   "source": [
    "Add some animals pcitures :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e006d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sottodirectory o file animals già esistente.\n"
     ]
    }
   ],
   "source": [
    "!mkdir animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e20e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
      "License(s): GPL-2.0\n",
      "animals10.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p animals alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eae6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf animals/animals10.zip -C animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88aa4686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing negative images (leedsbutterfly/images): 100%|██████████| 832/832 [01:18<00:00, 10.64item/s]\n",
      "Processing negative images (stanford-background-dataset/images): 100%|██████████| 715/715 [00:26<00:00, 26.85item/s]\n",
      "Processing negative images (animals/raw-img/gatto): 100%|██████████| 1668/1668 [03:22<00:00,  8.22item/s]\n",
      "Processing negative images (animals/raw-img/gallina): 100%|██████████| 3098/3098 [01:36<00:00, 31.99item/s]\n",
      "Processing negative images (animals/raw-img/mucca): 100%|██████████| 1866/1866 [00:57<00:00, 32.20item/s]\n",
      "Processing negative images (animals/raw-img/scoiattolo): 100%|██████████| 1862/1862 [01:01<00:00, 30.48item/s]\n",
      "Processing negative images (animals/raw-img/pecora): 100%|██████████| 1820/1820 [01:16<00:00, 23.80item/s]\n"
     ]
    }
   ],
   "source": [
    "#process negative images\n",
    "butterflies_img_dir = 'leedsbutterfly/images'\n",
    "background_img_dir = 'stanford-background-dataset/images'\n",
    "cat_img_dir = 'animals/raw-img/gatto'\n",
    "chicken_img_dir = 'animals/raw-img/gallina'\n",
    "cow_img_dir = 'animals/raw-img/mucca'\n",
    "squirrel_img_dir = 'animals/raw-img/scoiattolo'\n",
    "sheep_img_dir = 'animals/raw-img/pecora'\n",
    "negative_img_dirs = [butterflies_img_dir,\n",
    "                     background_img_dir,\n",
    "                     cat_img_dir,\n",
    "                     chicken_img_dir,\n",
    "                     cow_img_dir,\n",
    "                     squirrel_img_dir,\n",
    "                     sheep_img_dir                    \n",
    "                    ]\n",
    "\n",
    "# for directory in tqdm(negative_img_dirs,desc=\"Dataset:\",unit=\"item\"):\n",
    "for directory in negative_img_dirs:\n",
    "    for filename in tqdm(os.listdir(directory),desc=f\"Processing negative images ({directory})\",\n",
    "                        unit=\"item\"):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = imread(img_path, as_gray=True)\n",
    "\n",
    "            #image normalization in [0,1]\n",
    "            img_normalized = rescale_intensity(img, in_range='dtype', out_range=(0, 1))\n",
    "\n",
    "            process_image(img_normalized, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878afef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969741f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25094, 3781)\n"
     ]
    }
   ],
   "source": [
    "#Convert in numpy variables\n",
    "features_matrix = np.array(features_list)\n",
    "labels_array = np.array(labels_list).reshape(-1, 1)\n",
    "\n",
    "#this is the feature matrix, i.e. dataset for classification model\n",
    "final_matrix = np.hstack((features_matrix, labels_array))\n",
    "\n",
    "#check\n",
    "print(final_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c301bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1640b59",
   "metadata": {},
   "source": [
    "## Classification model (pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
