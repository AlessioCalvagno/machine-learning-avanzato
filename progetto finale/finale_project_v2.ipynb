{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bcac0e",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee30d68",
   "metadata": {},
   "source": [
    "La ProCam s.p.a ha intenzione di lanciare sul mercato una nuova fotocamera digitale compatta ed economica destinata a piccoli fotografi in erba.\n",
    "\n",
    "Vieni assunto come Data Scientist per realizzare il sistema di identificazione dei volti nelle immagini, questo permetterà poi ai tecnici della fotografia di ottimizzare le impostazioni per un selfie con una o più persone.\n",
    "\n",
    "Si tratta di un problema di computer vision, più precisamente di Face Detection.\n",
    "\n",
    "Devi fornire una pipeline scikit-learn che prende un'immagine in ingresso e ritorna una lista con le coordinate dei bounding box dove sono presenti dei volti, se nell'immagine non contiene volti la lista sarà ovviamente vuota."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa0e31",
   "metadata": {},
   "source": [
    "- Non ti viene fornito un dataset, sta a te cercarne uno in rete o, nella peggiore delle ipotesi, costruirlo, per semplicità non considereremo implicazioni sulle licenze ad utilizzo commerciale, si tratta pur sempre di un progetto didattico.\n",
    "- Non puoi utilizzare modelli pre-addestrati, devi addestrarlo tu utilizzando scikit-learn.\n",
    "- Stai lavorando su un sistema con ridotte capacità di calcolo, quindi il modello deve richiedere poche risorse di calcolo.\n",
    "- Ovviamente non ti vengono fornite indicazioni sull'implementazione, fai un'approfondita ricerca bibliografica per trovare la soluzione migliore da adottare, il notebook che consegnerai deve essere ben documentato, devi spiegare quali soluzioni hai adottato e perché ed ogni risorsa esterna (paper, blog post, codice github...) che hai utilizzato.\n",
    "- Il progetto è abbastanza complesso, ricorda che in caso ne avessi necessità puoi sempre chiedere aiuto ai tuoi coach nella Classe Virtuale di Machine Learning su Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e41c2",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1d8fb",
   "metadata": {},
   "source": [
    "Import object images from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c69ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc002b2",
   "metadata": {},
   "source": [
    "Butterfly dataset (832 images). \n",
    "\n",
    "It contains bufferflies images with some flowers and plants. With this dataset model can learn to detect naturalistic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbb93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/veeralakrishna/butterfly-dataset\n",
      "License(s): Community Data License Agreement - Permissive - Version 1.0\n",
      "butterfly-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download veeralakrishna/butterfly-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip butterfly-dataset.zip -d butterfly-dataset\n",
    "# !tar -xf butterfly-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072609cc",
   "metadata": {},
   "source": [
    "Background dataset (715 images).\n",
    "\n",
    "It contains some backgournd images, taken from streets and landscape photos. With this dataset model can learn to detect common background objects and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b96145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sottodirectory o file stanford-background-dataset gi� esistente.\n"
     ]
    }
   ],
   "source": [
    "!mkdir stanford-background-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5edff9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/balraj98/stanford-background-dataset\n",
      "License(s): other\n",
      "stanford-background-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p stanford-background-dataset balraj98/stanford-background-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18727b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip stanford-background-dataset.zip -d stanford-background-dataset\n",
    "# !tar -xf stanford-background-dataset/stanford-background-dataset.zip -C stanford-background-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa93d2a",
   "metadata": {},
   "source": [
    "Add some animals pcitures :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e006d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sottodirectory o file animals gi� esistente.\n"
     ]
    }
   ],
   "source": [
    "!mkdir animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e20e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
      "License(s): GPL-2.0\n",
      "animals10.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p animals alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eae6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xf animals/animals10.zip -C animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83836c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some modules\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from skimage.exposure import rescale_intensity\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ImageResizer import ImageResizer\n",
    "from HOGFeatureExtractor import HOGFeatureExtractor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import genhalflogistic\n",
    "from scipy.stats import powerlaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2178e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e9d7",
   "metadata": {},
   "source": [
    "Prima di tutto provo a leggere le immagini di esempio di sklearn e provo ad estrarre hog features da questo... Il resto dopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232acb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoort first dataset (faces)\n",
    "lfw_people = fetch_lfw_people(resize=1)\n",
    "\n",
    "images_positive = lfw_people.images\n",
    "#use only a portion of these images, to don't unbalance final dataset\n",
    "# indexes = np.random.choice(len(lfw_people.images),1600, replace=False)\n",
    "# images_positive = lfw_people.images[indexes]\n",
    "\n",
    "#some helper variables\n",
    "#size = 64 x 128 as original paper\n",
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "#init list to hold features arrays and labels\n",
    "features_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d886e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13233, 125, 94)\n",
      "(13233,)\n"
     ]
    }
   ],
   "source": [
    "X_positive = images_positive\n",
    "y_positive = np.ones(X_positive.shape[0])\n",
    "print(X_positive.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d17292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 94)\n"
     ]
    }
   ],
   "source": [
    "print(X_positive[1,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4aee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing negative images (leedsbutterfly/images):  49%|████▊     | 405/832 [00:11<00:11, 35.63item/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     25\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n\u001b[1;32m---> 26\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_gray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#this resize is necessary for concatenation in a single numpy array\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     img \u001b[38;5;241m=\u001b[39m resize(img, X_positive[\u001b[38;5;241m1\u001b[39m,:,:]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\skimage\\io\\manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:15\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\imageio\\v2.py:227\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mri\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimopen_args) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m--> 227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\imageio\\core\\legacy_plugin_wrapper.py:147\u001b[0m, in \u001b[0;36mLegacyPlugin.read\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([im \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)])\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[1;32m--> 147\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mget_data(index)\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\imageio\\core\\legacy_plugin_wrapper.py:116\u001b[0m, in \u001b[0;36mLegacyPlugin.legacy_get_reader\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format\u001b[38;5;241m.\u001b[39mget_reader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request\u001b[38;5;241m.\u001b[39mget_file()\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\imageio\\core\\format.py:221\u001b[0m, in \u001b[0;36mFormat.get_reader\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m select_mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodes:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFormat \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot read in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mimage_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m     )\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\imageio\\core\\format.py:312\u001b[0m, in \u001b[0;36mFormat._BaseReaderWriter.__init__\u001b[1;34m(self, format, request)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request \u001b[38;5;241m=\u001b[39m request\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# Open the reader/writer\u001b[39;00m\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\imageio\\plugins\\pillow_legacy.py:391\u001b[0m, in \u001b[0;36mPNGFormat.Reader._open\u001b[1;34m(self, pilmode, as_gray, ignoregamma)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, pilmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, as_gray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, ignoregamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPillowFormat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpilmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpilmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_gray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_gray\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\imageio\\plugins\\pillow_legacy.py:297\u001b[0m, in \u001b[0;36mPillowFormat.Reader._open\u001b[1;34m(self, pilmode, as_gray)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mdirty:\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mrawmode_saved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mrawmode\n\u001b[1;32m--> 297\u001b[0m \u001b[43mpil_try_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_im\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# Store args\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    300\u001b[0m     as_gray\u001b[38;5;241m=\u001b[39mas_gray, is_gray\u001b[38;5;241m=\u001b[39m_palette_is_grayscale(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_im)\n\u001b[0;32m    301\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\imageio\\plugins\\pillow_legacy.py:648\u001b[0m, in \u001b[0;36mpil_try_read\u001b[1;34m(im)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpil_try_read\u001b[39m(im):\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    647\u001b[0m         \u001b[38;5;66;03m# this will raise an IOError if the file is not readable\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m         \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    650\u001b[0m         site \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://pillow.readthedocs.io/en/latest/installation.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1358\u001b[0m, in \u001b[0;36mImage.getdata\u001b[1;34m(self, band)\u001b[0m\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetdata\u001b[39m(\u001b[38;5;28mself\u001b[39m, band\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;124;03m    Returns the contents of this image as a sequence object\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;124;03m    containing pixel values.  The sequence object is flattened, so\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1355\u001b[0m \u001b[38;5;124;03m    :returns: A sequence-like object.\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1358\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m band \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mgetband(band)\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\Lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#process negative images\n",
    "negative_images = []\n",
    "\n",
    "butterflies_img_dir = 'leedsbutterfly/images'\n",
    "background_img_dir = 'stanford-background-dataset/images'\n",
    "cat_img_dir = 'animals/raw-img/gatto'\n",
    "chicken_img_dir = 'animals/raw-img/gallina'\n",
    "cow_img_dir = 'animals/raw-img/mucca'\n",
    "squirrel_img_dir = 'animals/raw-img/scoiattolo'\n",
    "sheep_img_dir = 'animals/raw-img/pecora'\n",
    "negative_img_dirs = [butterflies_img_dir,\n",
    "                     background_img_dir,\n",
    "                     cat_img_dir,\n",
    "                     chicken_img_dir,\n",
    "                     cow_img_dir,\n",
    "                     squirrel_img_dir,\n",
    "                     sheep_img_dir                    \n",
    "                    ]\n",
    "\n",
    "# for directory in tqdm(negative_img_dirs,desc=\"Dataset:\",unit=\"item\"):\n",
    "for directory in negative_img_dirs:\n",
    "    for filename in tqdm(os.listdir(directory),desc=f\"Processing negative images ({directory})\",\n",
    "                        unit=\"item\"):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = imread(img_path, as_gray=True)\n",
    "            #this resize is necessary for concatenation in a single numpy array\n",
    "            img = resize(img, X_positive[1,:,:].shape)\n",
    "            negative_images.append(img)\n",
    "\n",
    "X_negative = np.array(negative_images)\n",
    "y_negative = np.zeros(X_negative.shape[0])\n",
    "print(X_negative.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((X_positive, X_negative))\n",
    "y = np.concatenate([y_positive,y_negative])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e93d9",
   "metadata": {},
   "source": [
    "Primo tentativo di pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e26070",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "# Definisci la pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('resizer', ImageResizer(resize_shape)),\n",
    "    ('hog', HOGFeatureExtractor()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(random_state=RANDOM_SEED)), \n",
    "    ('svc', SVC(max_iter=5000))\n",
    "]) \n",
    "# memory=\"pipe_cache\")\n",
    "\n",
    "\n",
    "# Addestra il modello (edit: si fa con il random search)\n",
    "#pipeline.fit(X, y)\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8194ce",
   "metadata": {},
   "source": [
    "Random search optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4d6f5",
   "metadata": {},
   "source": [
    "Effetto di C (deve essere positivo):\n",
    "- se C aumenta, ho più classificazioni corrette, ho margine più stretto e quindi meno vettori di supporto (fit più lungo per cercare i SV)\n",
    "- se C diminuiusce, ho più errori, ho margine più largo e quindi ho più vettori di supporto (predizione più lunga)\n",
    "\n",
    "Effetto di gamma (deve essere positivo):\n",
    "- se gamma aumenta, i vettori di supporto influenzano una zona più ristretta, quindi ottengo un decision boundary più accartocciato attorno ai SV (quindi più probabile overfitting)\n",
    "- se gamma diminuisce i SV influenzano una zona più larga, ho un decision boundary più liscio e semplice (perdo la forma dei dati, underfitting)\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html#sphx-glr-auto-examples-svm-plot-rbf-parameters-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniform distribution, such that all values are equally probable\n",
    "C_range = uniform(loc=0.001, scale=100.0)\n",
    "#lognorm distribution, such that lower values are more probable (if gamma is too high, decision boundary is too close to SV and i have overfitting)\n",
    "gamma_range = lognorm(s=0.95, loc=0, scale=1)\n",
    "degree_range = list(range(3,11))\n",
    "#i want negative skewness here (higher values are preferred)\n",
    "# n_components_range = powerlaw(3.7)\n",
    "n_components_range=[50,100,150,200]\n",
    "\n",
    "grid = [{\n",
    "    \"pca__n_components\":n_components_range,\n",
    "    \"svc__kernel\" : [\"rbf\"],\n",
    "    # \"svc__gamma\" : gamma_range,\n",
    "    \"svc__C\" : C_range\n",
    "}]\n",
    "# {\n",
    "#     \"pca__n_components\":n_components_range,\n",
    "#     \"svc__kernel\" : [\"poly\"],\n",
    "#     \"svc__gamma\" : gamma_range,\n",
    "#     \"svc__C\" : C_range,\n",
    "#     \"svc__degree\": degree_range\n",
    "# }]\n",
    "\n",
    "search = RandomizedSearchCV(estimator=pipeline,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=4,\n",
    "                            random_state=RANDOM_SEED,\n",
    "                            n_jobs=1)\n",
    "\n",
    "# x = np.linspace(genhalflogistic.ppf(0.01, 1),\n",
    "#                 genhalflogistic.ppf(0.99, 1), 100)\n",
    "# plt.plot(x, genhalflogistic.pdf(x, 1),\n",
    "#        'r-', lw=5, alpha=0.6, label='genhalflogistic pdf')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# b=3.7\n",
    "# x = np.linspace(powerlaw.ppf(0.01, b),\n",
    "#                 powerlaw.ppf(0.99, b), 100)\n",
    "# plt.plot(x, powerlaw.pdf(x, b),\n",
    "#        'r-', lw=5, alpha=0.6, label='powerlaw pdf')\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fa0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split is really needed? I could use whole dataset as train-valid set and use custom images as test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# search.fit(X_train, y_train)\n",
    "search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\")\n",
    "print(f\"Best accuracy: {search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64304b8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6582c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(search.best_estimator_,\"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pipeline.predict([X[-100,:,:]]))\n",
    "def sliding_window(image, step_size, window_size):\n",
    "    # get the window and image sizes\n",
    "    h, w = window_size\n",
    "    image_h, image_w = image.shape[:2]\n",
    "\n",
    "    # loop over the image, taking steps of size `step_size`\n",
    "    for y in range(0, image_h, step_size):\n",
    "        for x in range(0, image_w, step_size):\n",
    "            # define the window\n",
    "            window = image[y:y + h, x:x + w]\n",
    "            # if the window is below the minimum window size, ignore it\n",
    "            if window.shape[:2] != window_size:\n",
    "                continue\n",
    "            # yield the current window\n",
    "            yield (x, y, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54452793",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(\"img1.jpg\", as_gray=True)\n",
    "w, h = 64, 128 #replace with suitable values\n",
    "bounding_boxes = []\n",
    "\n",
    "for (x, y, window) in sliding_window(image, step_size=40, window_size=(w, h)):\n",
    "    prediction = search.predict(window)\n",
    "    #replace with saving bounding box info\n",
    "    if(prediction == 1):\n",
    "        print(f\"Face detected at ({x}, {y})\")\n",
    "        bounding_boxes.append((x,y,w,h)) # (x, y, width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04661b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "#display bounding boxes inside image\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "for (x, y, width, height) in bounding_boxes:\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=2, edgecolor='g', facecolor='none')\n",
    "    plt.gca().add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fe460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d45aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878afef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c301bc",
   "metadata": {},
   "source": [
    "# TODO: Inserire il random searchCV con la pipeline custom creata sopra\n",
    "\n",
    "https://scikit-learn.org/stable/modules/compose.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html#sphx-glr-auto-examples-compose-plot-digits-pipe-py\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
