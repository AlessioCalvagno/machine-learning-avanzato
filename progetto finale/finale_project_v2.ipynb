{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bcac0e",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee30d68",
   "metadata": {},
   "source": [
    "La ProCam s.p.a ha intenzione di lanciare sul mercato una nuova fotocamera digitale compatta ed economica destinata a piccoli fotografi in erba.\n",
    "\n",
    "Vieni assunto come Data Scientist per realizzare il sistema di identificazione dei volti nelle immagini, questo permetterà poi ai tecnici della fotografia di ottimizzare le impostazioni per un selfie con una o più persone.\n",
    "\n",
    "Si tratta di un problema di computer vision, più precisamente di Face Detection.\n",
    "\n",
    "Devi fornire una pipeline scikit-learn che prende un'immagine in ingresso e ritorna una lista con le coordinate dei bounding box dove sono presenti dei volti, se nell'immagine non contiene volti la lista sarà ovviamente vuota."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa0e31",
   "metadata": {},
   "source": [
    "- Non ti viene fornito un dataset, sta a te cercarne uno in rete o, nella peggiore delle ipotesi, costruirlo, per semplicità non considereremo implicazioni sulle licenze ad utilizzo commerciale, si tratta pur sempre di un progetto didattico.\n",
    "- Non puoi utilizzare modelli pre-addestrati, devi addestrarlo tu utilizzando scikit-learn.\n",
    "- Stai lavorando su un sistema con ridotte capacità di calcolo, quindi il modello deve richiedere poche risorse di calcolo.\n",
    "- Ovviamente non ti vengono fornite indicazioni sull'implementazione, fai un'approfondita ricerca bibliografica per trovare la soluzione migliore da adottare, il notebook che consegnerai deve essere ben documentato, devi spiegare quali soluzioni hai adottato e perché ed ogni risorsa esterna (paper, blog post, codice github...) che hai utilizzato.\n",
    "- Il progetto è abbastanza complesso, ricorda che in caso ne avessi necessità puoi sempre chiedere aiuto ai tuoi coach nella Classe Virtuale di Machine Learning su Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e41c2",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83836c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some modules\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from skimage.exposure import rescale_intensity\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e9d7",
   "metadata": {},
   "source": [
    "Prima di tutto provo a leggere le immagini di esempio di sklearn e provo ad estrarre hog features da questo... Il resto dopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232acb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoort first dataset (faces)\n",
    "lfw_people = fetch_lfw_people(resize=1)\n",
    "\n",
    "images_positive = lfw_people.images\n",
    "#use only a portion of these images, to don't unbalance final dataset\n",
    "# indexes = np.random.choice(len(lfw_people.images),1600, replace=False)\n",
    "# images_positive = lfw_people.images[indexes]\n",
    "\n",
    "#some helper variables\n",
    "#size = 64 x 128 as original paper\n",
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "#init list to hold features arrays and labels\n",
    "features_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d886e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13233, 125, 94)\n",
      "(13233,)\n"
     ]
    }
   ],
   "source": [
    "X_positive = images_positive\n",
    "y_positive = np.ones(X_positive.shape[0])\n",
    "print(X_positive.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d17292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 94)\n"
     ]
    }
   ],
   "source": [
    "print(X_positive[1,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4aee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing negative images (leedsbutterfly/images): 100%|██████████| 832/832 [00:24<00:00, 33.81item/s]\n",
      "Processing negative images (stanford-background-dataset/images): 100%|██████████| 715/715 [00:03<00:00, 235.88item/s]\n",
      "Processing negative images (animals/raw-img/gatto): 100%|██████████| 1668/1668 [01:28<00:00, 18.90item/s] \n",
      "Processing negative images (animals/raw-img/gallina): 100%|██████████| 3098/3098 [00:15<00:00, 199.77item/s]\n",
      "Processing negative images (animals/raw-img/mucca): 100%|██████████| 1866/1866 [00:09<00:00, 190.96item/s]\n",
      "Processing negative images (animals/raw-img/scoiattolo): 100%|██████████| 1862/1862 [00:10<00:00, 172.73item/s]\n",
      "Processing negative images (animals/raw-img/pecora): 100%|██████████| 1820/1820 [00:16<00:00, 112.01item/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11861, 125, 94)\n",
      "(11861,)\n"
     ]
    }
   ],
   "source": [
    "#process negative images\n",
    "negative_images = []\n",
    "\n",
    "butterflies_img_dir = 'leedsbutterfly/images'\n",
    "background_img_dir = 'stanford-background-dataset/images'\n",
    "cat_img_dir = 'animals/raw-img/gatto'\n",
    "chicken_img_dir = 'animals/raw-img/gallina'\n",
    "cow_img_dir = 'animals/raw-img/mucca'\n",
    "squirrel_img_dir = 'animals/raw-img/scoiattolo'\n",
    "sheep_img_dir = 'animals/raw-img/pecora'\n",
    "negative_img_dirs = [butterflies_img_dir,\n",
    "                     background_img_dir,\n",
    "                     cat_img_dir,\n",
    "                     chicken_img_dir,\n",
    "                     cow_img_dir,\n",
    "                     squirrel_img_dir,\n",
    "                     sheep_img_dir                    \n",
    "                    ]\n",
    "\n",
    "# for directory in tqdm(negative_img_dirs,desc=\"Dataset:\",unit=\"item\"):\n",
    "for directory in negative_img_dirs:\n",
    "    for filename in tqdm(os.listdir(directory),desc=f\"Processing negative images ({directory})\",\n",
    "                        unit=\"item\"):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = imread(img_path, as_gray=True)\n",
    "            #this resize is necessary for concatenation in a single numpy array\n",
    "            img = resize(img, X_positive[1,:,:].shape)\n",
    "            negative_images.append(img)\n",
    "\n",
    "X_negative = np.array(negative_images)\n",
    "y_negative = np.zeros(X_negative.shape[0])\n",
    "print(X_negative.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "399b397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25094, 125, 94)\n",
      "(25094,)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((X_positive, X_negative))\n",
    "y = np.concatenate([y_positive,y_negative])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e93d9",
   "metadata": {},
   "source": [
    "Primo tentativo di pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e26070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resize image: 100%|██████████| 25094/25094 [00:29<00:00, 857.08item/s]\n",
      "HOG feature extraction: 100%|██████████| 25094/25094 [01:10<00:00, 354.74item/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()), (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=100)),\n",
       "                (&#x27;svc&#x27;, SVC(kernel=&#x27;poly&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()), (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=100)),\n",
       "                (&#x27;svc&#x27;, SVC(kernel=&#x27;poly&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ImageResizer</label><div class=\"sk-toggleable__content\"><pre>ImageResizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HOGFeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>HOGFeatureExtractor()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=100)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('resizer', ImageResizer()), ('hog', HOGFeatureExtractor()),\n",
       "                ('scaler', StandardScaler()), ('pca', PCA(n_components=100)),\n",
       "                ('svc', SVC(kernel='poly'))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ImageResizer import ImageResizer\n",
    "from HOGFeatureExtractor import HOGFeatureExtractor\n",
    "\n",
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "# Definisci la pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('resizer', ImageResizer(resize_shape)),\n",
    "    ('hog', HOGFeatureExtractor()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=100)),  # Scegli il numero di componenti che desideri\n",
    "    ('svc', SVC(kernel='poly'))  # SVC con kernel polinomiale\n",
    "])\n",
    "\n",
    "# Addestra il modello\n",
    "pipeline.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41c0fd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resize image: 100%|██████████| 1/1 [00:00<00:00, 200.07item/s]\n",
      "HOG feature extraction: 100%|██████████| 1/1 [00:00<00:00, 165.59item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(pipeline.predict([X[-100,:,:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54452793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04661b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fe460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d45aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24d1d8fb",
   "metadata": {},
   "source": [
    "Import object images from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c69ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc002b2",
   "metadata": {},
   "source": [
    "Butterfly dataset (832 images). \n",
    "\n",
    "It contains bufferflies images with some flowers and plants. With this dataset model can learn to detect naturalistic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/veeralakrishna/butterfly-dataset\n",
      "License(s): Community Data License Agreement - Permissive - Version 1.0\n",
      "butterfly-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download veeralakrishna/butterfly-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip butterfly-dataset.zip -d butterfly-dataset\n",
    "!tar -xf butterfly-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072609cc",
   "metadata": {},
   "source": [
    "Background dataset (715 images).\n",
    "\n",
    "It contains some backgournd images, taken from streets and landscape photos. With this dataset model can learn to detect common background objects and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b96145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sottodirectory o file stanford-background-dataset già esistente.\n"
     ]
    }
   ],
   "source": [
    "!mkdir stanford-background-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edff9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/balraj98/stanford-background-dataset\n",
      "License(s): other\n",
      "stanford-background-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p stanford-background-dataset balraj98/stanford-background-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18727b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip stanford-background-dataset.zip -d stanford-background-dataset\n",
    "!tar -xf stanford-background-dataset/stanford-background-dataset.zip -C stanford-background-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa93d2a",
   "metadata": {},
   "source": [
    "Add some animals pcitures :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e006d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sottodirectory o file animals già esistente.\n"
     ]
    }
   ],
   "source": [
    "!mkdir animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
      "License(s): GPL-2.0\n",
      "animals10.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p animals alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf animals/animals10.zip -C animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878afef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c301bc",
   "metadata": {},
   "source": [
    "# TODO: Inserire il random searchCV con la pipeline custom creata sopra\n",
    "\n",
    "https://scikit-learn.org/stable/modules/compose.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html#sphx-glr-auto-examples-compose-plot-digits-pipe-py\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
