{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bcac0e",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee30d68",
   "metadata": {},
   "source": [
    "La ProCam s.p.a ha intenzione di lanciare sul mercato una nuova fotocamera digitale compatta ed economica destinata a piccoli fotografi in erba.\n",
    "\n",
    "Vieni assunto come Data Scientist per realizzare il sistema di identificazione dei volti nelle immagini, questo permetterà poi ai tecnici della fotografia di ottimizzare le impostazioni per un selfie con una o più persone.\n",
    "\n",
    "Si tratta di un problema di computer vision, più precisamente di Face Detection.\n",
    "\n",
    "Devi fornire una pipeline scikit-learn che prende un'immagine in ingresso e ritorna una lista con le coordinate dei bounding box dove sono presenti dei volti, se nell'immagine non contiene volti la lista sarà ovviamente vuota."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa0e31",
   "metadata": {},
   "source": [
    "- Non ti viene fornito un dataset, sta a te cercarne uno in rete o, nella peggiore delle ipotesi, costruirlo, per semplicità non considereremo implicazioni sulle licenze ad utilizzo commerciale, si tratta pur sempre di un progetto didattico.\n",
    "- Non puoi utilizzare modelli pre-addestrati, devi addestrarlo tu utilizzando scikit-learn.\n",
    "- Stai lavorando su un sistema con ridotte capacità di calcolo, quindi il modello deve richiedere poche risorse di calcolo.\n",
    "- Ovviamente non ti vengono fornite indicazioni sull'implementazione, fai un'approfondita ricerca bibliografica per trovare la soluzione migliore da adottare, il notebook che consegnerai deve essere ben documentato, devi spiegare quali soluzioni hai adottato e perché ed ogni risorsa esterna (paper, blog post, codice github...) che hai utilizzato.\n",
    "- Il progetto è abbastanza complesso, ricorda che in caso ne avessi necessità puoi sempre chiedere aiuto ai tuoi coach nella Classe Virtuale di Machine Learning su Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e41c2",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1d8fb",
   "metadata": {},
   "source": [
    "Import object images from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c69ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc002b2",
   "metadata": {},
   "source": [
    "Butterfly dataset (832 images). \n",
    "\n",
    "It contains bufferflies images with some flowers and plants. With this dataset model can learn to detect naturalistic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download veeralakrishna/butterfly-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip butterfly-dataset.zip -d butterfly-dataset\n",
    "# !tar -xf butterfly-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072609cc",
   "metadata": {},
   "source": [
    "Background dataset (715 images).\n",
    "\n",
    "It contains some backgournd images, taken from streets and landscape photos. With this dataset model can learn to detect common background objects and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b96145",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir stanford-background-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edff9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -p stanford-background-dataset balraj98/stanford-background-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18727b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip stanford-background-dataset.zip -d stanford-background-dataset\n",
    "# !tar -xf stanford-background-dataset/stanford-background-dataset.zip -C stanford-background-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa93d2a",
   "metadata": {},
   "source": [
    "Add some animals pcitures :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e006d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -p animals alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xf animals/animals10.zip -C animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83836c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some modules\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from skimage.exposure import rescale_intensity\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ImageResizer import ImageResizer\n",
    "from HOGFeatureExtractor import HOGFeatureExtractor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import genhalflogistic\n",
    "from scipy.stats import powerlaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e9d7",
   "metadata": {},
   "source": [
    "Prima di tutto provo a leggere le immagini di esempio di sklearn e provo ad estrarre hog features da questo... Il resto dopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232acb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoort first dataset (faces)\n",
    "lfw_people = fetch_lfw_people(resize=1)\n",
    "\n",
    "images_positive = lfw_people.images\n",
    "#use only a portion of these images, to don't unbalance final dataset\n",
    "# indexes = np.random.choice(len(lfw_people.images),1600, replace=False)\n",
    "# images_positive = lfw_people.images[indexes]\n",
    "\n",
    "#some helper variables\n",
    "#size = 64 x 128 as original paper\n",
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "#init list to hold features arrays and labels\n",
    "features_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d886e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_positive = images_positive\n",
    "y_positive = np.ones(X_positive.shape[0])\n",
    "print(X_positive.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d17292",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_positive[1,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4aee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process negative images\n",
    "negative_images = []\n",
    "\n",
    "butterflies_img_dir = 'leedsbutterfly/images'\n",
    "background_img_dir = 'stanford-background-dataset/images'\n",
    "cat_img_dir = 'animals/raw-img/gatto'\n",
    "chicken_img_dir = 'animals/raw-img/gallina'\n",
    "cow_img_dir = 'animals/raw-img/mucca'\n",
    "squirrel_img_dir = 'animals/raw-img/scoiattolo'\n",
    "sheep_img_dir = 'animals/raw-img/pecora'\n",
    "negative_img_dirs = [butterflies_img_dir,\n",
    "                     background_img_dir,\n",
    "                     cat_img_dir,\n",
    "                     chicken_img_dir,\n",
    "                     cow_img_dir,\n",
    "                     squirrel_img_dir,\n",
    "                     sheep_img_dir                    \n",
    "                    ]\n",
    "\n",
    "# for directory in tqdm(negative_img_dirs,desc=\"Dataset:\",unit=\"item\"):\n",
    "for directory in negative_img_dirs:\n",
    "    for filename in tqdm(os.listdir(directory),desc=f\"Processing negative images ({directory})\",\n",
    "                        unit=\"item\"):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = imread(img_path, as_gray=True)\n",
    "            #this resize is necessary for concatenation in a single numpy array\n",
    "            img = resize(img, X_positive[1,:,:].shape)\n",
    "            negative_images.append(img)\n",
    "\n",
    "X_negative = np.array(negative_images)\n",
    "y_negative = np.zeros(X_negative.shape[0])\n",
    "print(X_negative.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((X_positive, X_negative))\n",
    "y = np.concatenate([y_positive,y_negative])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e93d9",
   "metadata": {},
   "source": [
    "Primo tentativo di pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e26070",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "# Definisci la pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('resizer', ImageResizer(resize_shape)),\n",
    "    ('hog', HOGFeatureExtractor()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    # ('pca', PCA(n_components=100)),  # Scegli il numero di componenti che desideri\n",
    "    ('pca', PCA(svd_solver=\"full\")), \n",
    "    ('svc', SVC())  # SVC con kernel polinomiale\n",
    "], memory=\"pipe_cache\")\n",
    "\n",
    "\n",
    "# Addestra il modello (edit: si fa con il random search)\n",
    "#pipeline.fit(X, y)\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8194ce",
   "metadata": {},
   "source": [
    "Random search optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4d6f5",
   "metadata": {},
   "source": [
    "Effetto di C (deve essere positivo):\n",
    "- se C aumenta, ho più classificazioni corrette, ho margine più stretto e quindi meno vettori di supporto (fit più lungo per cercare i SV)\n",
    "- se C diminuiusce, ho più errori, ho margine più largo e quindi ho più vettori di supporto (predizione più lunga)\n",
    "\n",
    "Effetto di gamma (deve essere positivo):\n",
    "- se gamma aumenta, i vettori di supporto influenzano una zona più ristretta, quindi ottengo un decision boundary più accartocciato attorno ai SV (quindi più probabile overfitting)\n",
    "- se gamma diminuisce i SV influenzano una zona più larga, ho un decision boundary più liscio e semplice (perdo la forma dei dati, underfitting)\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html#sphx-glr-auto-examples-svm-plot-rbf-parameters-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniform distribution, such that all values are equally probable\n",
    "C_range = uniform(loc=0.001, scale=100.0)\n",
    "#lognorm distribution, such that lower values are more probable (if gamma is too high, decision boundary is too close to SV and i have overfitting)\n",
    "gamma_range = lognorm(s=0.95, loc=0, scale=1)\n",
    "degree_range = list(range(3,11))\n",
    "#i want negative skewness here (higher values are preferred)\n",
    "n_components_range = powerlaw(3.7)\n",
    "\n",
    "grid = [{\n",
    "    \"pca__n_components\":n_components_range,\n",
    "    \"svc__kernel\" : [\"rbf\"],\n",
    "    \"svc__gamma\" : gamma_range,\n",
    "    \"svc__C\" : C_range\n",
    "}]\n",
    "# {\n",
    "#     \"pca__n_components\":n_components_range,\n",
    "#     \"svc__kernel\" : [\"poly\"],\n",
    "#     \"svc__gamma\" : gamma_range,\n",
    "#     \"svc__C\" : C_range,\n",
    "#     \"svc__degree\": degree_range\n",
    "# }]\n",
    "\n",
    "search = RandomizedSearchCV(estimator=pipeline,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20,\n",
    "                            cv=10,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=4,\n",
    "                            random_state=RANDOM_SEED,\n",
    "                            n_jobs=1)\n",
    "\n",
    "# x = np.linspace(genhalflogistic.ppf(0.01, 1),\n",
    "#                 genhalflogistic.ppf(0.99, 1), 100)\n",
    "# plt.plot(x, genhalflogistic.pdf(x, 1),\n",
    "#        'r-', lw=5, alpha=0.6, label='genhalflogistic pdf')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# b=3.7\n",
    "# x = np.linspace(powerlaw.ppf(0.01, b),\n",
    "#                 powerlaw.ppf(0.99, b), 100)\n",
    "# plt.plot(x, powerlaw.pdf(x, b),\n",
    "#        'r-', lw=5, alpha=0.6, label='powerlaw pdf')\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fa0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\")\n",
    "print(f\"Best accuracy: {search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64304b8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(pipeline.predict([X[-100,:,:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54452793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04661b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fe460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d45aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878afef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c301bc",
   "metadata": {},
   "source": [
    "# TODO: Inserire il random searchCV con la pipeline custom creata sopra\n",
    "\n",
    "https://scikit-learn.org/stable/modules/compose.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html#sphx-glr-auto-examples-compose-plot-digits-pipe-py\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
