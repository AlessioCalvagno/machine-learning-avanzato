{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69bcac0e",
   "metadata": {},
   "source": [
    "## Face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee30d68",
   "metadata": {},
   "source": [
    "La ProCam s.p.a ha intenzione di lanciare sul mercato una nuova fotocamera digitale compatta ed economica destinata a piccoli fotografi in erba.\n",
    "\n",
    "Vieni assunto come Data Scientist per realizzare il sistema di identificazione dei volti nelle immagini, questo permetterà poi ai tecnici della fotografia di ottimizzare le impostazioni per un selfie con una o più persone.\n",
    "\n",
    "Si tratta di un problema di computer vision, più precisamente di Face Detection.\n",
    "\n",
    "Devi fornire una pipeline scikit-learn che prende un'immagine in ingresso e ritorna una lista con le coordinate dei bounding box dove sono presenti dei volti, se nell'immagine non contiene volti la lista sarà ovviamente vuota."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa0e31",
   "metadata": {},
   "source": [
    "- Non ti viene fornito un dataset, sta a te cercarne uno in rete o, nella peggiore delle ipotesi, costruirlo, per semplicità non considereremo implicazioni sulle licenze ad utilizzo commerciale, si tratta pur sempre di un progetto didattico.\n",
    "- Non puoi utilizzare modelli pre-addestrati, devi addestrarlo tu utilizzando scikit-learn.\n",
    "- Stai lavorando su un sistema con ridotte capacità di calcolo, quindi il modello deve richiedere poche risorse di calcolo.\n",
    "- Ovviamente non ti vengono fornite indicazioni sull'implementazione, fai un'approfondita ricerca bibliografica per trovare la soluzione migliore da adottare, il notebook che consegnerai deve essere ben documentato, devi spiegare quali soluzioni hai adottato e perché ed ogni risorsa esterna (paper, blog post, codice github...) che hai utilizzato.\n",
    "- Il progetto è abbastanza complesso, ricorda che in caso ne avessi necessità puoi sempre chiedere aiuto ai tuoi coach nella Classe Virtuale di Machine Learning su Discord."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e41c2",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/applications/plot_face_recognition.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1d8fb",
   "metadata": {},
   "source": [
    "Import object images from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c69ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc002b2",
   "metadata": {},
   "source": [
    "Butterfly dataset (832 images). \n",
    "\n",
    "It contains bufferflies images with some flowers and plants. With this dataset model can learn to detect naturalistic objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbb93d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/veeralakrishna/butterfly-dataset\n",
      "License(s): Community Data License Agreement - Permissive - Version 1.0\n",
      "butterfly-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download veeralakrishna/butterfly-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565766bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip butterfly-dataset.zip -d butterfly-dataset\n",
    "# !tar -xf butterfly-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072609cc",
   "metadata": {},
   "source": [
    "Background dataset (715 images).\n",
    "\n",
    "It contains some backgournd images, taken from streets and landscape photos. With this dataset model can learn to detect common background objects and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b96145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sottodirectory o file stanford-background-dataset gi� esistente.\n"
     ]
    }
   ],
   "source": [
    "!mkdir stanford-background-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5edff9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/balraj98/stanford-background-dataset\n",
      "License(s): other\n",
      "stanford-background-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p stanford-background-dataset balraj98/stanford-background-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18727b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip stanford-background-dataset.zip -d stanford-background-dataset\n",
    "# !tar -xf stanford-background-dataset/stanford-background-dataset.zip -C stanford-background-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa93d2a",
   "metadata": {},
   "source": [
    "Add some animals pcitures :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e006d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sottodirectory o file animals gi� esistente.\n"
     ]
    }
   ],
   "source": [
    "!mkdir animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e20e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
      "License(s): GPL-2.0\n",
      "animals10.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -p animals alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eae6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xf animals/animals10.zip -C animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83836c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some modules\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "from skimage.exposure import rescale_intensity\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ImageResizer import ImageResizer\n",
    "from HOGFeatureExtractor import HOGFeatureExtractor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import genhalflogistic\n",
    "from scipy.stats import powerlaw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2178e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48e9d7",
   "metadata": {},
   "source": [
    "Prima di tutto provo a leggere le immagini di esempio di sklearn e provo ad estrarre hog features da questo... Il resto dopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232acb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoort first dataset (faces)\n",
    "lfw_people = fetch_lfw_people(resize=1)\n",
    "\n",
    "images_positive = lfw_people.images\n",
    "#use only a portion of these images, to don't unbalance final dataset\n",
    "# indexes = np.random.choice(len(lfw_people.images),1600, replace=False)\n",
    "# images_positive = lfw_people.images[indexes]\n",
    "\n",
    "#some helper variables\n",
    "#size = 64 x 128 as original paper\n",
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "#init list to hold features arrays and labels\n",
    "features_list = []\n",
    "labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d886e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13233, 125, 94)\n",
      "(13233,)\n"
     ]
    }
   ],
   "source": [
    "X_positive = images_positive\n",
    "y_positive = np.ones(X_positive.shape[0])\n",
    "print(X_positive.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_positive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d17292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 94)\n"
     ]
    }
   ],
   "source": [
    "print(X_positive[1,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4aee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing negative images (leedsbutterfly/images): 100%|██████████| 832/832 [00:28<00:00, 28.97item/s]\n",
      "Processing negative images (stanford-background-dataset/images): 100%|██████████| 715/715 [00:03<00:00, 214.24item/s]\n",
      "Processing negative images (animals/raw-img/gatto): 100%|██████████| 1668/1668 [01:53<00:00, 14.64item/s] \n",
      "Processing negative images (animals/raw-img/gallina): 100%|██████████| 3098/3098 [00:20<00:00, 153.99item/s]\n",
      "Processing negative images (animals/raw-img/mucca): 100%|██████████| 1866/1866 [00:12<00:00, 152.69item/s]\n",
      "Processing negative images (animals/raw-img/scoiattolo): 100%|██████████| 1862/1862 [00:10<00:00, 173.08item/s]\n",
      "Processing negative images (animals/raw-img/pecora): 100%|██████████| 1820/1820 [00:17<00:00, 101.54item/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11861, 125, 94)\n",
      "(11861,)\n"
     ]
    }
   ],
   "source": [
    "#process negative images\n",
    "negative_images = []\n",
    "\n",
    "butterflies_img_dir = 'leedsbutterfly/images'\n",
    "background_img_dir = 'stanford-background-dataset/images'\n",
    "cat_img_dir = 'animals/raw-img/gatto'\n",
    "chicken_img_dir = 'animals/raw-img/gallina'\n",
    "cow_img_dir = 'animals/raw-img/mucca'\n",
    "squirrel_img_dir = 'animals/raw-img/scoiattolo'\n",
    "sheep_img_dir = 'animals/raw-img/pecora'\n",
    "negative_img_dirs = [butterflies_img_dir,\n",
    "                     background_img_dir,\n",
    "                     cat_img_dir,\n",
    "                     chicken_img_dir,\n",
    "                     cow_img_dir,\n",
    "                     squirrel_img_dir,\n",
    "                     sheep_img_dir                    \n",
    "                    ]\n",
    "\n",
    "# for directory in tqdm(negative_img_dirs,desc=\"Dataset:\",unit=\"item\"):\n",
    "for directory in negative_img_dirs:\n",
    "    for filename in tqdm(os.listdir(directory),desc=f\"Processing negative images ({directory})\",\n",
    "                        unit=\"item\"):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = imread(img_path, as_gray=True)\n",
    "            #this resize is necessary for concatenation in a single numpy array\n",
    "            img = resize(img, X_positive[1,:,:].shape)\n",
    "            negative_images.append(img)\n",
    "\n",
    "X_negative = np.array(negative_images)\n",
    "y_negative = np.zeros(X_negative.shape[0])\n",
    "print(X_negative.shape) #3 dimensions: 1 = records, 2-3 = image as matrix \n",
    "print(y_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "399b397b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25094, 125, 94)\n",
      "(25094,)\n"
     ]
    }
   ],
   "source": [
    "X = np.vstack((X_positive, X_negative))\n",
    "y = np.concatenate([y_positive,y_negative])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e93d9",
   "metadata": {},
   "source": [
    "Primo tentativo di pipeline..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3e26070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()), (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(random_state=200)),\n",
       "                (&#x27;svc&#x27;, SVC(max_iter=5000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()), (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(random_state=200)),\n",
       "                (&#x27;svc&#x27;, SVC(max_iter=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ImageResizer</label><div class=\"sk-toggleable__content\"><pre>ImageResizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HOGFeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>HOGFeatureExtractor()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(random_state=200)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(max_iter=5000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('resizer', ImageResizer()), ('hog', HOGFeatureExtractor()),\n",
       "                ('scaler', StandardScaler()), ('pca', PCA(random_state=200)),\n",
       "                ('svc', SVC(max_iter=5000))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_shape = (128, 64) #as row x columns (h x w)\n",
    "\n",
    "# Definisci la pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('resizer', ImageResizer(resize_shape)),\n",
    "    ('hog', HOGFeatureExtractor()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(random_state=RANDOM_SEED)), \n",
    "    ('svc', SVC(max_iter=5000))\n",
    "]) \n",
    "# memory=\"pipe_cache\")\n",
    "\n",
    "\n",
    "# Addestra il modello (edit: si fa con il random search)\n",
    "#pipeline.fit(X, y)\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8194ce",
   "metadata": {},
   "source": [
    "Random search optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4d6f5",
   "metadata": {},
   "source": [
    "Effetto di C (deve essere positivo):\n",
    "- se C aumenta, ho più classificazioni corrette, ho margine più stretto e quindi meno vettori di supporto (fit più lungo per cercare i SV)\n",
    "- se C diminuiusce, ho più errori, ho margine più largo e quindi ho più vettori di supporto (predizione più lunga)\n",
    "\n",
    "Effetto di gamma (deve essere positivo):\n",
    "- se gamma aumenta, i vettori di supporto influenzano una zona più ristretta, quindi ottengo un decision boundary più accartocciato attorno ai SV (quindi più probabile overfitting)\n",
    "- se gamma diminuisce i SV influenzano una zona più larga, ho un decision boundary più liscio e semplice (perdo la forma dei dati, underfitting)\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html#sphx-glr-auto-examples-svm-plot-rbf-parameters-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c33b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniform distribution, such that all values are equally probable\n",
    "C_range = uniform(loc=0.001, scale=100.0)\n",
    "#lognorm distribution, such that lower values are more probable (if gamma is too high, decision boundary is too close to SV and i have overfitting)\n",
    "gamma_range = lognorm(s=0.95, loc=0, scale=1)\n",
    "degree_range = list(range(3,11))\n",
    "#i want negative skewness here (higher values are preferred)\n",
    "# n_components_range = powerlaw(3.7)\n",
    "n_components_range=[50,100,150,200]\n",
    "\n",
    "grid = [{\n",
    "    \"pca__n_components\":n_components_range,\n",
    "    \"svc__kernel\" : [\"rbf\"],\n",
    "    # \"svc__gamma\" : gamma_range,\n",
    "    \"svc__C\" : C_range\n",
    "}]\n",
    "# {\n",
    "#     \"pca__n_components\":n_components_range,\n",
    "#     \"svc__kernel\" : [\"poly\"],\n",
    "#     \"svc__gamma\" : gamma_range,\n",
    "#     \"svc__C\" : C_range,\n",
    "#     \"svc__degree\": degree_range\n",
    "# }]\n",
    "\n",
    "search = RandomizedSearchCV(estimator=pipeline,\n",
    "                            param_distributions=grid,\n",
    "                            n_iter=20,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\",\n",
    "                            verbose=4,\n",
    "                            random_state=RANDOM_SEED,\n",
    "                            n_jobs=1)\n",
    "\n",
    "# x = np.linspace(genhalflogistic.ppf(0.01, 1),\n",
    "#                 genhalflogistic.ppf(0.99, 1), 100)\n",
    "# plt.plot(x, genhalflogistic.pdf(x, 1),\n",
    "#        'r-', lw=5, alpha=0.6, label='genhalflogistic pdf')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# b=3.7\n",
    "# x = np.linspace(powerlaw.ppf(0.01, b),\n",
    "#                 powerlaw.ppf(0.99, b), 100)\n",
    "# plt.plot(x, powerlaw.pdf(x, b),\n",
    "#        'r-', lw=5, alpha=0.6, label='powerlaw pdf')\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "196fa0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20075, 125, 94)\n",
      "(5019, 125, 94)\n",
      "(20075,)\n",
      "(5019,)\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END pca__n_components=150, svc__C=49.41536292718904, svc__kernel=rbf;, score=0.998 total time= 2.0min\n",
      "[CV 2/5] END pca__n_components=150, svc__C=49.41536292718904, svc__kernel=rbf;, score=0.998 total time= 1.8min\n",
      "[CV 3/5] END pca__n_components=150, svc__C=49.41536292718904, svc__kernel=rbf;, score=0.997 total time= 1.9min\n",
      "[CV 4/5] END pca__n_components=150, svc__C=49.41536292718904, svc__kernel=rbf;, score=0.997 total time= 2.6min\n",
      "[CV 5/5] END pca__n_components=150, svc__C=49.41536292718904, svc__kernel=rbf;, score=0.999 total time= 2.4min\n",
      "[CV 1/5] END pca__n_components=50, svc__C=59.443014439113256, svc__kernel=rbf;, score=0.997 total time= 1.9min\n",
      "[CV 2/5] END pca__n_components=50, svc__C=59.443014439113256, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=50, svc__C=59.443014439113256, svc__kernel=rbf;, score=0.997 total time= 1.5min\n",
      "[CV 4/5] END pca__n_components=50, svc__C=59.443014439113256, svc__kernel=rbf;, score=0.996 total time= 1.5min\n",
      "[CV 5/5] END pca__n_components=50, svc__C=59.443014439113256, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=50, svc__C=57.39414762066355, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 2/5] END pca__n_components=50, svc__C=57.39414762066355, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 3/5] END pca__n_components=50, svc__C=57.39414762066355, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 4/5] END pca__n_components=50, svc__C=57.39414762066355, svc__kernel=rbf;, score=0.996 total time= 1.3min\n",
      "[CV 5/5] END pca__n_components=50, svc__C=57.39414762066355, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=150, svc__C=0.287059168094277, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=150, svc__C=0.287059168094277, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 3/5] END pca__n_components=150, svc__C=0.287059168094277, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 4/5] END pca__n_components=150, svc__C=0.287059168094277, svc__kernel=rbf;, score=0.995 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=150, svc__C=0.287059168094277, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=100, svc__C=43.579580699633716, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 2/5] END pca__n_components=100, svc__C=43.579580699633716, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 3/5] END pca__n_components=100, svc__C=43.579580699633716, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 4/5] END pca__n_components=100, svc__C=43.579580699633716, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 5/5] END pca__n_components=100, svc__C=43.579580699633716, svc__kernel=rbf;, score=0.999 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=150, svc__C=45.60909854582528, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 2/5] END pca__n_components=150, svc__C=45.60909854582528, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 3/5] END pca__n_components=150, svc__C=45.60909854582528, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 4/5] END pca__n_components=150, svc__C=45.60909854582528, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 5/5] END pca__n_components=150, svc__C=45.60909854582528, svc__kernel=rbf;, score=0.999 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=200, svc__C=96.7485666607596, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=200, svc__C=96.7485666607596, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=200, svc__C=96.7485666607596, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=200, svc__C=96.7485666607596, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=200, svc__C=96.7485666607596, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=100, svc__C=98.60375114020934, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 2/5] END pca__n_components=100, svc__C=98.60375114020934, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 3/5] END pca__n_components=100, svc__C=98.60375114020934, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=100, svc__C=98.60375114020934, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 5/5] END pca__n_components=100, svc__C=98.60375114020934, svc__kernel=rbf;, score=0.999 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=150, svc__C=70.68195825887719, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=150, svc__C=70.68195825887719, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=150, svc__C=70.68195825887719, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=150, svc__C=70.68195825887719, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=150, svc__C=70.68195825887719, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=50, svc__C=84.61134903175555, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 2/5] END pca__n_components=50, svc__C=84.61134903175555, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 3/5] END pca__n_components=50, svc__C=84.61134903175555, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 4/5] END pca__n_components=50, svc__C=84.61134903175555, svc__kernel=rbf;, score=0.996 total time= 1.3min\n",
      "[CV 5/5] END pca__n_components=50, svc__C=84.61134903175555, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=150, svc__C=18.723056437713122, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=150, svc__C=18.723056437713122, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=150, svc__C=18.723056437713122, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=150, svc__C=18.723056437713122, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=150, svc__C=18.723056437713122, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=200, svc__C=25.05150547710023, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=200, svc__C=25.05150547710023, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=200, svc__C=25.05150547710023, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=200, svc__C=25.05150547710023, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=200, svc__C=25.05150547710023, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=200, svc__C=51.73622229752766, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=200, svc__C=51.73622229752766, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=200, svc__C=51.73622229752766, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=200, svc__C=51.73622229752766, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=200, svc__C=51.73622229752766, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=200, svc__C=82.60601471973274, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=200, svc__C=82.60601471973274, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=200, svc__C=82.60601471973274, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=200, svc__C=82.60601471973274, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=200, svc__C=82.60601471973274, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=200, svc__C=81.66296187846393, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=200, svc__C=81.66296187846393, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=200, svc__C=81.66296187846393, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=200, svc__C=81.66296187846393, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=200, svc__C=81.66296187846393, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=50, svc__C=57.8385690105367, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 2/5] END pca__n_components=50, svc__C=57.8385690105367, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 3/5] END pca__n_components=50, svc__C=57.8385690105367, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 4/5] END pca__n_components=50, svc__C=57.8385690105367, svc__kernel=rbf;, score=0.996 total time= 1.3min\n",
      "[CV 5/5] END pca__n_components=50, svc__C=57.8385690105367, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=150, svc__C=56.77450437652839, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=150, svc__C=56.77450437652839, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=150, svc__C=56.77450437652839, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=150, svc__C=56.77450437652839, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=150, svc__C=56.77450437652839, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=200, svc__C=41.94356213164552, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=200, svc__C=41.94356213164552, svc__kernel=rbf;, score=0.999 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=200, svc__C=41.94356213164552, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=200, svc__C=41.94356213164552, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=200, svc__C=41.94356213164552, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 1/5] END pca__n_components=50, svc__C=81.93292899872087, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 2/5] END pca__n_components=50, svc__C=81.93292899872087, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 3/5] END pca__n_components=50, svc__C=81.93292899872087, svc__kernel=rbf;, score=0.997 total time= 1.3min\n",
      "[CV 4/5] END pca__n_components=50, svc__C=81.93292899872087, svc__kernel=rbf;, score=0.996 total time= 1.3min\n",
      "[CV 5/5] END pca__n_components=50, svc__C=81.93292899872087, svc__kernel=rbf;, score=0.998 total time= 1.3min\n",
      "[CV 1/5] END pca__n_components=100, svc__C=10.54441072821876, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 2/5] END pca__n_components=100, svc__C=10.54441072821876, svc__kernel=rbf;, score=0.998 total time= 1.4min\n",
      "[CV 3/5] END pca__n_components=100, svc__C=10.54441072821876, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 4/5] END pca__n_components=100, svc__C=10.54441072821876, svc__kernel=rbf;, score=0.997 total time= 1.4min\n",
      "[CV 5/5] END pca__n_components=100, svc__C=10.54441072821876, svc__kernel=rbf;, score=0.999 total time= 1.4min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()),\n",
       "                                             (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;pca&#x27;, PCA(random_state=200)),\n",
       "                                             (&#x27;svc&#x27;, SVC(max_iter=5000))]),\n",
       "                   n_iter=20, n_jobs=1,\n",
       "                   param_distributions=[{&#x27;pca__n_components&#x27;: [50, 100, 150,\n",
       "                                                               200],\n",
       "                                         &#x27;svc__C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002F03EDF8610&gt;,\n",
       "                                         &#x27;svc__kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "                   random_state=200, scoring=&#x27;accuracy&#x27;, verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()),\n",
       "                                             (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;pca&#x27;, PCA(random_state=200)),\n",
       "                                             (&#x27;svc&#x27;, SVC(max_iter=5000))]),\n",
       "                   n_iter=20, n_jobs=1,\n",
       "                   param_distributions=[{&#x27;pca__n_components&#x27;: [50, 100, 150,\n",
       "                                                               200],\n",
       "                                         &#x27;svc__C&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002F03EDF8610&gt;,\n",
       "                                         &#x27;svc__kernel&#x27;: [&#x27;rbf&#x27;]}],\n",
       "                   random_state=200, scoring=&#x27;accuracy&#x27;, verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()), (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(random_state=200)),\n",
       "                (&#x27;svc&#x27;, SVC(max_iter=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ImageResizer</label><div class=\"sk-toggleable__content\"><pre>ImageResizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HOGFeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>HOGFeatureExtractor()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(random_state=200)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(max_iter=5000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('resizer', ImageResizer()),\n",
       "                                             ('hog', HOGFeatureExtractor()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('pca', PCA(random_state=200)),\n",
       "                                             ('svc', SVC(max_iter=5000))]),\n",
       "                   n_iter=20, n_jobs=1,\n",
       "                   param_distributions=[{'pca__n_components': [50, 100, 150,\n",
       "                                                               200],\n",
       "                                         'svc__C': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000002F03EDF8610>,\n",
       "                                         'svc__kernel': ['rbf']}],\n",
       "                   random_state=200, scoring='accuracy', verbose=4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=RANDOM_SEED)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3c5c8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'pca__n_components': 200, 'svc__C': 96.7485666607596, 'svc__kernel': 'rbf'}\n",
      "Best accuracy: 0.9976089663760896\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {search.best_params_}\")\n",
    "print(f\"Best accuracy: {search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5425bb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()), (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=200, random_state=200)),\n",
       "                (&#x27;svc&#x27;, SVC(C=96.7485666607596, max_iter=5000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;resizer&#x27;, ImageResizer()), (&#x27;hog&#x27;, HOGFeatureExtractor()),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=200, random_state=200)),\n",
       "                (&#x27;svc&#x27;, SVC(C=96.7485666607596, max_iter=5000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ImageResizer</label><div class=\"sk-toggleable__content\"><pre>ImageResizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HOGFeatureExtractor</label><div class=\"sk-toggleable__content\"><pre>HOGFeatureExtractor()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=200, random_state=200)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=96.7485666607596, max_iter=5000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('resizer', ImageResizer()), ('hog', HOGFeatureExtractor()),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('pca', PCA(n_components=200, random_state=200)),\n",
       "                ('svc', SVC(C=96.7485666607596, max_iter=5000))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64304b8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41c0fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(pipeline.predict([X[-100,:,:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54452793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04661b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fe460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d45aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878afef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68c301bc",
   "metadata": {},
   "source": [
    "# TODO: Inserire il random searchCV con la pipeline custom creata sopra\n",
    "\n",
    "https://scikit-learn.org/stable/modules/compose.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_digits_pipe.html#sphx-glr-auto-examples-compose-plot-digits-pipe-py\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
